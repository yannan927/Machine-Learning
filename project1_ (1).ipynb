{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ku_UYezvd7Sb"
   },
   "source": [
    "Now Reading The Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F0jo6DCbk63e"
   },
   "outputs": [],
   "source": [
    "! kill -9 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached https://files.pythonhosted.org/packages/58/26/6b86448bda61c1ce463ad2c962641a933113f4496de16085df41217cdccc/torch-1.6.0-cp37-none-macosx_10_9_x86_64.whl\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from torch) (1.16.4)\n",
      "Collecting future (from torch)\n",
      "  Using cached https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz\n",
      "Installing collected packages: future, torch\n",
      "  Running setup.py install for future ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed future-0.18.2 torch-1.6.0\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 20.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "57nWqET0FJs5"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "l7l_UYmcGwpX",
    "outputId": "5abf2120-3f80-41aa-e2fe-c46e7f5885e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:00, 29430.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file_name = '/Users/yannangao/PycharmProjects/sml/data/train.txt'\n",
    "\n",
    "train_data = []\n",
    "with open(file_name, 'r') as file:\n",
    "    for line in tqdm(file):\n",
    "        train_data.append(line)\n",
    "        \n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "TMMrXtvoGxLW",
    "outputId": "b455145a-69c9-4ec5-d627-f9d61e88b258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540762\t1912140\t1537559\t3091331\t2757277\t3237295\t1070876\t4008078\t1824878\t1005927\t2703564\t2519640\t3370407\t3883660\t2173241\t1726071\t2451654\t3906434\t2635670\t3294915\t2763417\t1116703\t261881\t2404108\t3521384\t2299939\t2989624\t4361289\t3314815\t3367669\t641925\t2862019\t1274046\t4316209\t2463912\t3043\t952976\t3532986\t415955\t4366854\t267263\t1199298\t1840280\t581535\t4241326\t4267183\t2881471\t2737722\t4286284\t333573\t1594907\t3056533\t2163471\t3712732\t2672578\t1209171\t1003239\t4818002\t3201437\t1892251\t2800259\t141083\t2558493\t1655093\t4313335\t738638\t3702208\t1124524\t1436216\t3206499\t1462439\t2345899\t4131275\t1169783\t2152173\t4174165\t141067\t3118623\t1521082\t3912913\t299865\t193736\t3562621\t94742\t2464827\t1719625\t557514\t1313296\t2329535\t3662772\t3980998\t695775\t381025\t3349332\t3704614\t1392121\t3767319\t1157186\t4230834\t1411138\t1312847\t1818911\t3820661\t1927780\t400117\t1853195\t3994838\t1327933\t3386592\t3766535\t343833\t4582129\t892512\t3316576\t3011333\t2673351\t746711\t2770509\t3670190\t4208653\t1970076\t2183328\t2492020\t289918\t1436562\t2335027\t3133671\t977117\t851113\t4467395\t611426\t3142255\t4575690\t3575966\t661185\t3541155\t4762204\t4075641\t69174\t506428\t151344\t3586135\t3886121\t1737397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k9HKbrZMGxmZ",
    "outputId": "f777263b-3854-40b7-d4b8-6225b1ffff5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "# store the root user and his follows\n",
    "from collections import defaultdict\n",
    "\n",
    "pair_list = []\n",
    "\n",
    "for item in train_data:\n",
    "    temp_data = item.split()\n",
    "    if len(temp_data) > 1:\n",
    "        follows_list = []\n",
    "        for i in range(len(temp_data)-1):\n",
    "            follows_list.append(temp_data[i+1])\n",
    "        pair_list.append((temp_data[0], follows_list))\n",
    "    else:\n",
    "        pair_list.append((temp_data[0], []))\n",
    "\n",
    "print(len(pair_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IkxKraCyU6VL",
    "outputId": "75ab7701-766b-46fc-e457-4ba73c5cbe05"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:00<00:00, 165857.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Node pairs length is 19570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# remove the node with no follows and change the id to '<unk>' if follows no greater than 5\n",
    "\n",
    "new_node_pair = []\n",
    "unk_follow_list = []\n",
    "\n",
    "for pair in tqdm(pair_list):\n",
    "    if len(pair[1]) > 0:\n",
    "      if len(pair[1]) <= 5:\n",
    "        new_node_pair.append(('unk', pair[1]))\n",
    "        unk_follow_list.append(pair[1])\n",
    "      elif len(pair[1]) <= 100:\n",
    "        new_node_pair.append((pair[0], pair[1]))\n",
    "      else:\n",
    "        new_node_pair.append((pair[0], pair[1][:100]))\n",
    "\n",
    "print('\\nThe Node pairs length is {}'.format(len(new_node_pair)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unk follows is 1795\n"
     ]
    }
   ],
   "source": [
    "unk_follows = []\n",
    "for item in unk_follow_list:\n",
    "    for follow in item:\n",
    "        unk_follows.append(follow)\n",
    "\n",
    "print('The number of unk follows is {}'.format(len(unk_follows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xXkpWgnYYEC6",
    "outputId": "9a38fc57-756b-4d19-dabc-ce09fae54a4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now process 100 files!\n",
      "Now process 200 files!\n",
      "Now process 300 files!\n",
      "Now process 400 files!\n",
      "Now process 500 files!\n",
      "Now process 600 files!\n",
      "Now process 700 files!\n",
      "Now process 800 files!\n",
      "Now process 900 files!\n",
      "Now process 1000 files!\n",
      "Now process 1100 files!\n",
      "Now process 1200 files!\n",
      "Now process 1300 files!\n",
      "Now process 1400 files!\n",
      "Now process 1500 files!\n",
      "Now process 1600 files!\n",
      "Now process 1700 files!\n",
      "Now process 1800 files!\n",
      "Now process 1900 files!\n",
      "Now process 2000 files!\n",
      "Now process 2100 files!\n",
      "Now process 2200 files!\n",
      "Now process 2300 files!\n",
      "Now process 2400 files!\n",
      "Now process 2500 files!\n",
      "Now process 2600 files!\n",
      "Now process 2700 files!\n",
      "Now process 2800 files!\n",
      "Now process 2900 files!\n",
      "Now process 3000 files!\n",
      "Now process 3100 files!\n",
      "Now process 3200 files!\n",
      "Now process 3300 files!\n",
      "Now process 3400 files!\n",
      "Now process 3500 files!\n",
      "Now process 3600 files!\n",
      "Now process 3700 files!\n",
      "Now process 3800 files!\n",
      "Now process 3900 files!\n",
      "Now process 4000 files!\n",
      "Now process 4100 files!\n",
      "Now process 4200 files!\n",
      "Now process 4300 files!\n",
      "Now process 4400 files!\n",
      "Now process 4500 files!\n",
      "Now process 4600 files!\n",
      "Now process 4700 files!\n",
      "Now process 4800 files!\n",
      "Now process 4900 files!\n",
      "Now process 5000 files!\n",
      "Now process 5100 files!\n",
      "Now process 5200 files!\n",
      "Now process 5300 files!\n",
      "Now process 5400 files!\n",
      "Now process 5500 files!\n",
      "Now process 5600 files!\n",
      "Now process 5700 files!\n",
      "Now process 5800 files!\n",
      "Now process 5900 files!\n",
      "Now process 6000 files!\n",
      "Now process 6100 files!\n",
      "Now process 6200 files!\n",
      "Now process 6300 files!\n",
      "Now process 6400 files!\n",
      "Now process 6500 files!\n",
      "Now process 6600 files!\n",
      "Now process 6700 files!\n",
      "Now process 6800 files!\n",
      "Now process 6900 files!\n",
      "Now process 7000 files!\n",
      "Now process 7100 files!\n",
      "Now process 7200 files!\n",
      "Now process 7300 files!\n",
      "Now process 7400 files!\n",
      "Now process 7500 files!\n",
      "Now process 7600 files!\n",
      "Now process 7700 files!\n",
      "Now process 7800 files!\n",
      "Now process 7900 files!\n",
      "Now process 8000 files!\n",
      "Now process 8100 files!\n",
      "Now process 8200 files!\n",
      "Now process 8300 files!\n",
      "Now process 8400 files!\n",
      "Now process 8500 files!\n",
      "Now process 8600 files!\n",
      "Now process 8700 files!\n",
      "Now process 8800 files!\n",
      "Now process 8900 files!\n",
      "Now process 9000 files!\n",
      "Now process 9100 files!\n",
      "Now process 9200 files!\n",
      "Now process 9300 files!\n",
      "Now process 9400 files!\n",
      "Now process 9500 files!\n",
      "Now process 9600 files!\n",
      "Now process 9700 files!\n",
      "Now process 9800 files!\n",
      "Now process 9900 files!\n",
      "Now process 10000 files!\n",
      "Now process 10100 files!\n",
      "Now process 10200 files!\n",
      "Now process 10300 files!\n",
      "Now process 10400 files!\n",
      "Now process 10500 files!\n",
      "Now process 10600 files!\n",
      "Now process 10700 files!\n",
      "Now process 10800 files!\n",
      "Now process 10900 files!\n",
      "Now process 11000 files!\n",
      "Now process 11100 files!\n",
      "Now process 11200 files!\n",
      "Now process 11300 files!\n",
      "Now process 11400 files!\n",
      "Now process 11500 files!\n",
      "Now process 11600 files!\n",
      "Now process 11700 files!\n",
      "Now process 11800 files!\n",
      "Now process 11900 files!\n",
      "Now process 12000 files!\n",
      "Now process 12100 files!\n",
      "Now process 12200 files!\n",
      "Now process 12300 files!\n",
      "Now process 12400 files!\n",
      "Now process 12500 files!\n",
      "Now process 12600 files!\n",
      "Now process 12700 files!\n",
      "Now process 12800 files!\n",
      "Now process 12900 files!\n",
      "Now process 13000 files!\n",
      "Now process 13100 files!\n",
      "Now process 13200 files!\n",
      "Now process 13300 files!\n",
      "Now process 13400 files!\n",
      "Now process 13500 files!\n",
      "Now process 13600 files!\n",
      "Now process 13700 files!\n",
      "Now process 13800 files!\n",
      "Now process 13900 files!\n",
      "Now process 14000 files!\n",
      "Now process 14100 files!\n",
      "Now process 14200 files!\n",
      "Now process 14300 files!\n",
      "Now process 14400 files!\n",
      "Now process 14500 files!\n",
      "Now process 14600 files!\n",
      "Now process 14700 files!\n",
      "Now process 14800 files!\n",
      "Now process 14900 files!\n",
      "Now process 15000 files!\n",
      "Now process 15100 files!\n",
      "Now process 15200 files!\n",
      "Now process 15300 files!\n",
      "Now process 15400 files!\n",
      "Now process 15500 files!\n",
      "Now process 15600 files!\n",
      "Now process 15700 files!\n",
      "Now process 15800 files!\n",
      "Now process 15900 files!\n",
      "Now process 16000 files!\n",
      "Now process 16100 files!\n",
      "Now process 16200 files!\n",
      "Now process 16300 files!\n",
      "Now process 16400 files!\n",
      "Now process 16500 files!\n",
      "Now process 16600 files!\n",
      "Now process 16700 files!\n",
      "Now process 16800 files!\n",
      "Now process 16900 files!\n",
      "Now process 17000 files!\n",
      "Now process 17100 files!\n",
      "Now process 17200 files!\n",
      "Now process 17300 files!\n",
      "Now process 17400 files!\n",
      "Now process 17500 files!\n",
      "Now process 17600 files!\n",
      "Now process 17700 files!\n",
      "Now process 17800 files!\n",
      "Now process 17900 files!\n",
      "Now process 18000 files!\n",
      "Now process 18100 files!\n",
      "Now process 18200 files!\n",
      "Now process 18300 files!\n",
      "Now process 18400 files!\n",
      "Now process 18500 files!\n",
      "Now process 18600 files!\n",
      "Now process 18700 files!\n",
      "Now process 18800 files!\n",
      "Now process 18900 files!\n",
      "Now process 19000 files!\n",
      "Now process 19100 files!\n",
      "Now process 19200 files!\n",
      "Now process 19300 files!\n",
      "Now process 19400 files!\n",
      "Now process 19500 files!\n",
      "18862\n"
     ]
    }
   ],
   "source": [
    "# Generate the negative samples\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_neg_data(original_data, length):\n",
    "    neg_dict = defaultdict(list)\n",
    "    count = 0\n",
    "\n",
    "    for item in original_data:\n",
    "        temp_list = []\n",
    "\n",
    "        while len(temp_list) < length:\n",
    "            random_num = random.randint(0, 5000000)\n",
    "            if item[0] == '<unk>':\n",
    "               if str(random_num) not in unk_follows:\n",
    "                  temp_list.append(str(random_num))\n",
    "            elif str(random_num) != item[0] and str(random_num) not in item[1]:\n",
    "                temp_list.append(str(random_num))\n",
    "        neg_dict[item[0]] = temp_list\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print('Now process {} files!'.format(count))\n",
    "    \n",
    "    return neg_dict\n",
    "\n",
    "neg_dict = get_neg_data(new_node_pair, 20)\n",
    "print(len(neg_dict))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "klclxnmFY9R_",
    "outputId": "b13d81ec-f784-4bb1-cfdc-4ff56968a8a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1540302\n"
     ]
    }
   ],
   "source": [
    "def get_id_pair(data_list):\n",
    "    pairs_list = []\n",
    "    for item in data_list:\n",
    "        for follows in item[1]:\n",
    "            pairs_list.append((item[0], follows))\n",
    "\n",
    "    return pairs_list\n",
    "\n",
    "pos_pair = get_id_pair(new_node_pair) # All the node Pair\n",
    "\n",
    "print(len(pos_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train pos pair is 1232241\n",
      "The length of dev pos pair is 308061\n"
     ]
    }
   ],
   "source": [
    "# Now Create positive train samples and dev samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_pos_pair, dev_pos_pair = train_test_split(pos_pair, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print('The length of train pos pair is {}'.format(len(train_pos_pair)))\n",
    "print('The length of dev pos pair is {}'.format(len(dev_pos_pair)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FnVTDp0So525",
    "outputId": "c2f341e7-f1c3-4d94-d391-e77e9150e39b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544026\n"
     ]
    }
   ],
   "source": [
    "# Build up a node set\n",
    "node_set = set()\n",
    "\n",
    "for pair in train_pos_pair:\n",
    "    node_set.add(pair[0])\n",
    "    node_set.add(pair[1])\n",
    "      \n",
    "print(len(node_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RA9S_Fw9pnnR",
    "outputId": "44adc2a7-e388-48e8-ef85-7e3ca4c1164c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544027\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Build Up node2idx dict in the format as node2idx['123456'] = 123(index)\n",
    "node2idx = {}\n",
    "node2idx['<unk>'] = 0\n",
    "\n",
    "for i, item in enumerate(node_set):\n",
    "    node2idx[item] = i + 1\n",
    "\n",
    "print(len(node2idx))\n",
    "print(node2idx['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o92DeFz4YI-8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1232241/1232241 [00:02<00:00, 492120.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train neg list is 1232241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Each pos sample give a negtive sample\n",
    "\n",
    "def build_neg_list(pos_pairs):\n",
    "  neg_list = []\n",
    "  for pair in tqdm(pos_pairs):\n",
    "      temp_list = []\n",
    "      neg_samples = random.choice(neg_dict[pair[0]])\n",
    "      neg_list.append(neg_samples)\n",
    "\n",
    "  return neg_list\n",
    "\n",
    "train_neg_list = build_neg_list(train_pos_pair)\n",
    "\n",
    "print('The length of train neg list is {}'.format(len(train_neg_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9gkGchjzkW48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "The length of dev pairs is 2000\n",
      "The length of dev label is 2000\n"
     ]
    }
   ],
   "source": [
    "# Now create the dev neg samples and dev labels so that to assess the model\n",
    "\n",
    "def create_neg_pair(dev_data):\n",
    "    neg_list = []\n",
    "    for pair in dev_data:\n",
    "        neg_sample = random.choice(neg_dict[pair[0]])\n",
    "        neg_list.append((pair[0], neg_sample))\n",
    "\n",
    "    return neg_list\n",
    "\n",
    "\n",
    "dev_pos_pair = random.sample(dev_pos_pair, 1000)\n",
    "dev_neg_pair = create_neg_pair(dev_pos_pair)\n",
    "print(len(dev_neg_pair))\n",
    "\n",
    "dev_pair = dev_pos_pair + dev_neg_pair\n",
    "print('The length of dev pairs is {}'.format(len(dev_pair)))\n",
    "dev_label = [1] * len(dev_pos_pair) + [0] * len(dev_neg_pair)\n",
    "print('The length of dev label is {}'.format(len(dev_label))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T-ScNexicztC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of dev_data is 2000\n",
      "The first component if dev_data is (('3739473', '2635123'), 1)\n",
      "Now we got a 2000 length dev pairs and labels\n"
     ]
    }
   ],
   "source": [
    "# combine the dev pair and dev label\n",
    "dev_data = []\n",
    "for i in range(len(dev_pair)):  \n",
    "    dev_data.append((dev_pair[i], dev_label[i]))\n",
    "\n",
    "print('The length of dev_data is {}'.format(len(dev_data)))\n",
    "print('The first component if dev_data is {}'.format(dev_data[0]))\n",
    "\n",
    "# Now we will shuffle the dev_data and pick 2000 samples\n",
    "random.shuffle(dev_data)\n",
    "print('Now we got a {} length dev pairs and labels'.format(len(dev_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uO08Q3rcbkRE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train_idx_data is 1232241\n"
     ]
    }
   ],
   "source": [
    "# transfer the id pair into index pair\n",
    "def build_up_vec(data):\n",
    "    index_pair = []\n",
    "    for pair in data:\n",
    "       pair_list = []\n",
    "       if pair[0] in node2idx.keys():\n",
    "          index1 = node2idx[pair[0]]\n",
    "       else:\n",
    "          index1 = node2idx['<unk>']\n",
    "       pair_list.append(index1)\n",
    "       if pair[1] in node2idx.keys():\n",
    "          index2 = node2idx[pair[1]]\n",
    "       else:\n",
    "         index2 = node2idx['<unk>']\n",
    "       pair_list.append(index2)\n",
    "       index_pair.append(pair_list)\n",
    "    \n",
    "    return index_pair\n",
    "\n",
    "train_idx_data = build_up_vec(train_pos_pair)\n",
    "\n",
    "print('The length of train_idx_data is {}'.format(len(train_idx_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Iv4xrNINqhk6",
    "outputId": "0aa20a2e-71c4-4509-daac-0487b2f9a8e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1369257, 2])\n",
      "torch.Size([342315, 2])\n"
     ]
    }
   ],
   "source": [
    "# transfer the id pair into index pair\n",
    "def build_up_vec(data):\n",
    "    index_pair = []\n",
    "    for pair in data:\n",
    "       pair_list = []\n",
    "       if pair[0] in node2idx.keys():\n",
    "          index1 = node2idx[pair[0]]\n",
    "       else:\n",
    "          index1 = node2idx['<unk>']\n",
    "       pair_list.append(index1)\n",
    "       if pair[1] in node2idx.keys():\n",
    "          index2 = node2idx[pair[1]]\n",
    "       else:\n",
    "         index2 = node2idx['<unk>']\n",
    "       pair_list.append(index2)\n",
    "       index_pair.append(pair_list)\n",
    "    \n",
    "    return index_pair\n",
    "\n",
    "train_idx_data = build_up_vec(train_pos_pair)\n",
    "\n",
    "print('The length of train_idx_data is {}'.format(len(train_idx_data)))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jS7q9SKmVqY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1232241/1232241 [00:01<00:00, 1121929.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train negative sample list is 1232241\n",
      "The first component of train_neg_list is 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert neg ids in to index\n",
    "train_neg_idx = []\n",
    "for neg in tqdm(train_neg_list):\n",
    "    if neg in node2idx.keys():\n",
    "        train_neg_idx.append(node2idx[neg])\n",
    "    else:\n",
    "        train_neg_idx.append(node2idx['<unk>'])\n",
    "\n",
    "\n",
    "print('The length of train negative sample list is {}'.format(len(train_neg_idx)))\n",
    "print('The first component of train_neg_list is {}'.format(train_neg_idx[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "mMeWGqACtkic",
    "outputId": "1614d922-4809-498a-800a-ba5f689399ba"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = len(node2idx)\n",
    "\n",
    "def look_up_table(word_idx):\n",
    "    x = torch.zeros(vocabulary_size).float()\n",
    "    x[word_idx] = 1.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ez8Z6sNxXGU"
   },
   "source": [
    "Now Build Up Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xv3PzEmXikg1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no GPU available, using the CPU instead!\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "embedding_dims = 50\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"There are {} GPUs available.\".format(torch.cuda.device_count()))\n",
    "    print(\"We will use GPU {}\".format(torch.cuda.get_device_name(0)))\n",
    "else:\n",
    "    print(\"There is no GPU available, using the CPU instead!\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RnIQVaz3imGp"
   },
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    return abs(dot(a, b)/(norm(a)*norm(b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCWxZjIGi9gv"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    returns accuracy per batch\n",
    "    \"\"\"\n",
    "    correct = (class_preds == y).astype(float) # convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "3rx5h-GpfL9Q",
    "outputId": "15d624a6-a9a9-4a8a-96a5-bb7e3bef92b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5046/1232241 [5:39:44<1377:05:16,  4.04s/it]    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-0a78ea72c590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# propagate the error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# gradient descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The two weight matrices:\n",
    "W1 = torch.randn(embedding_dims, vocabulary_size, requires_grad=True)\n",
    "W2 = torch.randn(embedding_dims, vocabulary_size, requires_grad=True)\n",
    "\n",
    "\n",
    "W1 = Variable(W1.to(device), requires_grad=True)\n",
    "W2 = Variable(W2.to(device), requires_grad=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i in tqdm(range(len(train_idx_data))):\n",
    "\n",
    "        data = train_idx_data[i][0]\n",
    "        target = train_idx_data[i][1]\n",
    "        \n",
    "\n",
    "        x_var = Variable(look_up_table(data)).float()\n",
    "        y_pos_var = Variable(look_up_table(target)).float()\n",
    "\n",
    "        # pick a negative sample\n",
    "        neg_sample = train_neg_idx[i]\n",
    "        y_neg_var = Variable(look_up_table(neg_sample)).float()\n",
    "        # use the look up table\n",
    "\n",
    "        x_emb = torch.matmul(W1, x_var)\n",
    "        y_pos_emb = torch.matmul(W2, y_pos_var)\n",
    "        y_neg_emb = torch.matmul(W2, y_neg_var)\n",
    "\n",
    "\n",
    "        # get positive sample score\n",
    "        pos_loss = nn.functional.logsigmoid(torch.matmul(x_emb, y_pos_emb))\n",
    "        \n",
    "        # get negative sample score\n",
    "        neg_loss = nn.functional.logsigmoid(-1 * torch.matmul(x_emb, y_neg_emb))\n",
    "        \n",
    "        # TO DO: compute loss\n",
    "     \n",
    "        loss = - (pos_loss + neg_loss.sum())\n",
    "\n",
    "    \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # propagate the error\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient descent\n",
    "        W1.data -= learning_rate * W1.grad.data\n",
    "        W2.data -= learning_rate * W2.grad.data\n",
    "\n",
    "        # zero out gradient accumulation\n",
    "        W1.grad.data.zero_()\n",
    "        W2.grad.data.zero_()\n",
    "\n",
    "\n",
    "    print(f'Loss at epoch {epoch}: {epoch_loss/len(train_idx_data)}')\n",
    "\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for dev_data in tqdm(dev_pair):\n",
    "        dev_id_pair = dev_data[0]\n",
    "        dev_label = dev_data[1]\n",
    "        labels.append(dev_label)\n",
    "\n",
    "        dev_idx = [node2idx[node_id] for node_id in dev_id_pair]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dev_x_var = look_up_table(dev_idx[0]).float()\n",
    "            dev_y_pos = look_up_table(dev_idx[1]).float()\n",
    "\n",
    "            dev_x_emb = torch.matmul(W1, x_var)\n",
    "            dev_y_pos_emb = torch.matmul(W2, y_pos_var)\n",
    "\n",
    "            x_vec = dev_x_emb.numpy()\n",
    "            y_vec = dev_y_pos_emb.numpy()\n",
    "\n",
    "            cosine_score = cosine_sim(x_vec, y_vec)\n",
    "\n",
    "            if cosine_score > 0.5:\n",
    "                preds.append(1)\n",
    "            else:\n",
    "                preds.append(0)\n",
    "    \n",
    "    dev_accuracy = accuracy(np.array(preds), np.array(labels))\n",
    "\n",
    "    print(f'The accyracy on the dev data is {dev_accuracy:.4f}')\n",
    "\n",
    "print('Training Process Complete!')  \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uvQquV86vNLn"
   },
   "source": [
    "Now we perform analysis on Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MiZjXEtnulsd"
   },
   "outputs": [],
   "source": [
    "def list2vec(data_list):\n",
    "    temp_list = []\n",
    "    for item in data_list:\n",
    "      temp_list.extend(list(item))\n",
    "\n",
    "    return np.array(temp_list)\n",
    "\n",
    "val_pred_arr = list2vec(best_val_preds)\n",
    "val_labels_arr - list2vec(best_val_labels)\n",
    "\n",
    "print(val_pred_arr.shape)\n",
    "print(val_labels_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GPfp4uNRwIkb"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(val_labels_arr, val_pred_arr)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "class_list = ['positive', 'negative']\n",
    "plot_confusion_matrix(cm, class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tk0FrA6XlLdS"
   },
   "outputs": [],
   "source": [
    "# Read the Test set\n",
    "\n",
    "test_file = 'test-public.txt'\n",
    "\n",
    "id_list = []\n",
    "root_list = []\n",
    "follows_list = []\n",
    "\n",
    "with open(test_file, \"r\") as file:\n",
    "  next(file)\n",
    "  for line in file:\n",
    "      line = line.strip().split()\n",
    "      id_list.append(line[0])\n",
    "      root_list.append(line[1])\n",
    "      follows_list.append(line[2])\n",
    "\n",
    "print(len(id_list))\n",
    "print(len(root_list))\n",
    "print(len(follows_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "dbPRRigHdtjK",
    "outputId": "18e5e42a-0c7c-470f-89cc-61145ea456e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "def id2idx(data):\n",
    "   idx = []\n",
    "   for id in data:\n",
    "     if id in node2idx.keys():\n",
    "          index = node2idx[id]\n",
    "     else:\n",
    "          index = node2idx['<unk>']\n",
    "\n",
    "     idx.append(index)\n",
    "  \n",
    "   return idx\n",
    "\n",
    "root_arr = id2idx(root_list)\n",
    "follows_arr = id2idx(follows_list)\n",
    "\n",
    "print(root_arr.shape)\n",
    "print(follows_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "baE7d4IINGCo",
    "outputId": "f8b1359b-b40e-40f2-f8c5-5315547894a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "torch.Size([2000, 2])\n"
     ]
    }
   ],
   "source": [
    "test_pair = []\n",
    "\n",
    "for i in range(len(root_arr)):\n",
    "    test_pair.append([root_arr[i], follows_arr[i]])\n",
    "\n",
    "print(len(test_pair))\n",
    "\n",
    "test_tensor = torch.LongTensor(test_pair)\n",
    "\n",
    "print(test_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vnqEol1TiY4v",
    "outputId": "5c915266-89bb-424e-fa64-0d8a3ea763bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 100\n",
    "\n",
    "test_data = TensorDataset(test_tensor)\n",
    "test_loader = DataLoader(test_data, batch_size=test_batch_size, shuffle=False)\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ohyuzvm6jjTg",
    "outputId": "e28ac327-ddc3-4f1a-d0c8-f8aa3aad7c35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def get_result(test_loader, model):\n",
    "    result = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "\n",
    "            test_input = batch[0].cuda()\n",
    "  \n",
    "            outputs = model(test_input)\n",
    "            preds = outputs.detach().cpu().numpy()\n",
    "\n",
    "            pred_result = np.argmax(softmax(preds), axis=1)\n",
    "            for score in pred_result:\n",
    "              result.append(score)\n",
    "    return np.array(result)\n",
    "\n",
    "pred = get_result(test_loader, model)\n",
    "print(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5B5wmVktllOB"
   },
   "outputs": [],
   "source": [
    "score_dict = {'Id':id_list, 'Predicted':pred}\n",
    "score_df = pd.DataFrame(score_dict)\n",
    "score_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "project1 .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
